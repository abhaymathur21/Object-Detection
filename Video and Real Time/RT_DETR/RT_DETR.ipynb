{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https:\\github.com\\ultralytics\\assets\\releases\\download\\v0.0.0\\rtdetr-l.pt to rtdetr-l.pt...\n",
      "100%|██████████| 63.4M/63.4M [00:11<00:00, 5.80MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names:  {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '10', 11: '11', 12: '12', 13: '13', 14: '14', 15: '15', 16: '16', 17: '17', 18: '18', 19: '19', 20: '20', 21: '21', 22: '22', 23: '23', 24: '24', 25: '25', 26: '26', 27: '27', 28: '28', 29: '29', 30: '30', 31: '31', 32: '32', 33: '33', 34: '34', 35: '35', 36: '36', 37: '37', 38: '38', 39: '39', 40: '40', 41: '41', 42: '42', 43: '43', 44: '44', 45: '45', 46: '46', 47: '47', 48: '48', 49: '49', 50: '50', 51: '51', 52: '52', 53: '53', 54: '54', 55: '55', 56: '56', 57: '57', 58: '58', 59: '59', 60: '60', 61: '61', 62: '62', 63: '63', 64: '64', 65: '65', 66: '66', 67: '67', 68: '68', 69: '69', 70: '70', 71: '71', 72: '72', 73: '73', 74: '74', 75: '75', 76: '76', 77: '77', 78: '78', 79: '79'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.132  Python-3.11.4 torch-2.0.1+cpu CPU\n",
      "rt-detr-l summary: 494 layers, 32148140 parameters, 0 gradients\n",
      "\n",
      "0: 640x640 1 0, 3 57s, 1 63, 1445.8ms\n",
      "Speed: 8.4ms preprocess, 1445.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "0: 640x640 1 0, 1 57, 2 59s, 1 62, 1183.7ms\n",
      "Speed: 4.0ms preprocess, 1183.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "0: 640x640 1 0, 2 57s, 1 62, 2 67s, 1313.6ms\n",
      "Speed: 7.2ms preprocess, 1313.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "0: 640x640 1 0, 1 57, 1 59, 1 63, 3 67s, 1255.2ms\n",
      "Speed: 8.5ms preprocess, 1255.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "0: 640x640 1 0, 1 59, 1 62, 1 65, 1 67, 1137.1ms\n",
      "Speed: 6.6ms preprocess, 1137.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "0: 640x640 1 0, 1 59, 1 67, 1107.1ms\n",
      "Speed: 3.6ms preprocess, 1107.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "0: 640x640 1 0, 1 59, 1084.5ms\n",
      "Speed: 3.5ms preprocess, 1084.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "0: 640x640 1 0, 1 59, 1160.6ms\n",
      "Speed: 4.0ms preprocess, 1160.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "\n",
      "0: 640x640 1 0, 1 59, 1094.2ms\n",
      "Speed: 5.0ms preprocess, 1094.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics.vit import RTDETR\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time \n",
    "import supervision as sv\n",
    "import pandas as pd\n",
    "\n",
    "class DETRClass:\n",
    "    def __init__(self,capture_index):\n",
    "        self.capture_index = capture_index\n",
    "        \n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        \n",
    "        print(\"Using device: \", self.device)\n",
    "        \n",
    "        self.model = RTDETR(\"rtdetr-l.pt\")\n",
    "        \n",
    "        self.CLASS_NAMES_DICT = self.model.model.names\n",
    "        \n",
    "        print(\"Class names: \", self.CLASS_NAMES_DICT)\n",
    "        \n",
    "        self.box_annotator = sv.BoxAnnotator(sv.ColorPalette.default(), thickness=3, text_thickness=3,text_scale=1.5)\n",
    "        \n",
    "    def plot_bboxes(self, results, frame):\n",
    "        #Extract the results\n",
    "        boxes=results[0].boxes.cpu().numpy()\n",
    "        class_id = boxes.cls\n",
    "        conf = boxes.conf\n",
    "        xyxy = boxes.xyxy\n",
    "        \n",
    "        class_id = class_id.astype(np.int32)\n",
    "        \n",
    "        \n",
    "        detections = sv.Detections(xyxy=xyxy, class_id=class_id, confidence = conf)\n",
    "        \n",
    "        self.labels = [f\"{self.CLASS_NAMES_DICT[class_id]} {confidence:.2f}\" for xyxy,confidence, class_id,track_id in detections]\n",
    "        \n",
    "        frame = self.box_annotator.annotate(frame,detections,self.labels)\n",
    "        return frame\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __call__(self):\n",
    "        cap =cv2.VideoCapture(self.capture_index)\n",
    "        assert cap.isOpened()\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            start_time = time.perf_counter()\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            results = self.model.predict(frame)\n",
    "            \n",
    "            frame = self.plot_bboxes(results, frame)\n",
    "            \n",
    "            end_time = time.perf_counter()\n",
    "            fps = 1/ (end_time - start_time)\n",
    "            \n",
    "            cv2.putText(frame, f\"FPS: {fps:.2f}\",(20,70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "            \n",
    "            cv2.imshow(\"DETR\", frame)\n",
    "            \n",
    "            if cv2.waitKey(1) == 27 or cv2.getWindowProperty(\"DETR\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "transformer_detector = DETRClass(0)\n",
    "transformer_detector()\n",
    "            \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
