{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cpu\n",
      "Class names:  {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '10', 11: '11', 12: '12', 13: '13', 14: '14', 15: '15', 16: '16', 17: '17', 18: '18', 19: '19', 20: '20', 21: '21', 22: '22', 23: '23', 24: '24', 25: '25', 26: '26', 27: '27', 28: '28', 29: '29', 30: '30', 31: '31', 32: '32', 33: '33', 34: '34', 35: '35', 36: '36', 37: '37', 38: '38', 39: '39', 40: '40', 41: '41', 42: '42', 43: '43', 44: '44', 45: '45', 46: '46', 47: '47', 48: '48', 49: '49', 50: '50', 51: '51', 52: '52', 53: '53', 54: '54', 55: '55', 56: '56', 57: '57', 58: '58', 59: '59', 60: '60', 61: '61', 62: '62', 63: '63', 64: '64', 65: '65', 66: '66', 67: '67', 68: '68', 69: '69', 70: '70', 71: '71', 72: '72', 73: '73', 74: '74', 75: '75', 76: '76', 77: '77', 78: '78', 79: '79'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.132  Python-3.11.4 torch-2.0.1+cpu CPU\n",
      "rt-detr-l summary: 494 layers, 32148140 parameters, 0 gradients\n",
      "\n",
      "0: 640x640 1 0, 3 57s, 1628.1ms\n",
      "Speed: 6.0ms preprocess, 1628.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict24\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Detections.__init__() missing 1 required positional argument: 'class_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 73\u001b[0m\n\u001b[0;32m     69\u001b[0m         cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     72\u001b[0m transformer_detector \u001b[39m=\u001b[39m DETRClass(\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 73\u001b[0m transformer_detector()\n",
      "Cell \u001b[1;32mIn[1], line 57\u001b[0m, in \u001b[0;36mDETRClass.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n\u001b[0;32m     55\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(frame)\n\u001b[1;32m---> 57\u001b[0m frame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplot_bboxes(results, frame)\n\u001b[0;32m     59\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m     60\u001b[0m fps \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39m (end_time \u001b[39m-\u001b[39m start_time)\n",
      "Cell \u001b[1;32mIn[1], line 35\u001b[0m, in \u001b[0;36mDETRClass.plot_bboxes\u001b[1;34m(self, results, frame)\u001b[0m\n\u001b[0;32m     30\u001b[0m xyxy \u001b[39m=\u001b[39m boxes\u001b[39m.\u001b[39mxyxy\n\u001b[0;32m     32\u001b[0m \u001b[39m# class_id = class_id.astype(np.int32)\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m detections \u001b[39m=\u001b[39m sv\u001b[39m.\u001b[39;49mDetections(xyxy\u001b[39m=\u001b[39;49mxyxy, confidence \u001b[39m=\u001b[39;49m conf)\n\u001b[0;32m     37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCLASS_NAMES_DICT[class_id]\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconfidence\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m xyxy,confidence, class_id,track_id \u001b[39min\u001b[39;00m detections]\n\u001b[0;32m     39\u001b[0m frame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbox_annotator\u001b[39m.\u001b[39mannotate(frame,detections,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels)\n",
      "\u001b[1;31mTypeError\u001b[0m: Detections.__init__() missing 1 required positional argument: 'class_id'"
     ]
    }
   ],
   "source": [
    "from ultralytics.vit import RTDETR\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time \n",
    "import supervision as sv\n",
    "import pandas as pd\n",
    "\n",
    "class DETRClass:\n",
    "    def __init__(self,capture_index):\n",
    "        self.capture_index = capture_index\n",
    "        \n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        \n",
    "        print(\"Using device: \", self.device)\n",
    "        \n",
    "        self.model = RTDETR(\"rtdetr-l.pt\")\n",
    "        \n",
    "        self.CLASS_NAMES_DICT = self.model.model.names\n",
    "        \n",
    "        print(\"Class names: \", self.CLASS_NAMES_DICT)\n",
    "        \n",
    "        self.box_annotator = sv.BoxAnnotator(sv.ColorPalette.default(), thickness=3, text_thickness=3,text_scale=1.5)\n",
    "        \n",
    "    def plot_bboxes(self, results, frame):\n",
    "        #Extract the results\n",
    "        boxes=results[0].boxes.cpu().numpy()\n",
    "        class_id = boxes.cls\n",
    "        conf = boxes.conf\n",
    "        xyxy = boxes.xyxy\n",
    "        \n",
    "        class_id = class_id.astype(np.int32)\n",
    "        \n",
    "        \n",
    "        detections = sv.Detections(xyxy=xyxy, class_id=class_id, confidence = conf)\n",
    "        \n",
    "        self.labels = [f\"{self.CLASS_NAMES_DICT[class_id]} {confidence:.2f}\" for xyxy,confidence, class_id,track_id in detections]\n",
    "        \n",
    "        frame = self.box_annotator.annotate(frame,detections,self.labels)\n",
    "        return frame\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __call__(self):\n",
    "        cap =cv2.VideoCapture(self.capture_index)\n",
    "        assert cap.isOpened()\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            start_time = time.perf_counter()\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            results = self.model.predict(frame)\n",
    "            \n",
    "            frame = self.plot_bboxes(results, frame)\n",
    "            \n",
    "            end_time = time.perf_counter()\n",
    "            fps = 1/ (end_time - start_time)\n",
    "            \n",
    "            cv2.putText(frame, f\"FPS: {fps:.2f}\",(20,70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "            \n",
    "            cv2.imshow(\"DETR\", frame)\n",
    "            \n",
    "            if cv2.waitKey(1) == 27 or cv2.getWindowProperty(\"DETR\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "transformer_detector = DETRClass(0)\n",
    "transformer_detector()\n",
    "            \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
